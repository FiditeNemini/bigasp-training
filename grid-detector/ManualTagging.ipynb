{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Manual Tagging\n",
    "\n",
    "Manually tagging images as to whether are a grid of thumbnails or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotImageClassification\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets as widgets\n",
    "from collections import defaultdict, OrderedDict\n",
    "import io\n",
    "import sqlite3\n",
    "from model import NsfwClassifier\n",
    "import json\n",
    "import base64\n",
    "from ipywidgets import HTML\n",
    "from IPython.display import display, Javascript\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = AutoModelForZeroShotImageClassification.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../data/clip-embeddings.sqlite3')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT path FROM images WHERE embedding IS NOT NULL\")\n",
    "all_paths = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "random_paths = random.sample(all_paths, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find likely bad content using zero-shot\n",
    "@torch.no_grad()\n",
    "def zero_shot_search(text: str) -> list[float]:\n",
    "\t# Get image embeddings\n",
    "\tembeddings = []\n",
    "\tfor path in random_paths:\n",
    "\t\tcursor.execute(\"SELECT embedding FROM images WHERE path = ?\", (path,))\n",
    "\t\tembedding = bytes(cursor.fetchone()[0])\n",
    "\t\tembedding = torch.frombuffer(bytearray(embedding), dtype=torch.float16)\n",
    "\t\tembeddings.append(embedding.to(torch.float32))\n",
    "\n",
    "\timage_embeds = torch.stack(embeddings)\n",
    "\timage_embeds = clip_model.visual_projection(image_embeds)\n",
    "\n",
    "\t# Get text embedding\n",
    "\tinputs = clip_processor(text=[text], return_tensors=\"pt\", padding=True)\n",
    "\ttext_embeds = clip_model.get_text_features(**inputs)\n",
    "\n",
    "\t# Normalize embeddings\n",
    "\timage_embeds = image_embeds / image_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "\ttext_embeds = text_embeds / text_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "\n",
    "\t# Cosine similarity as logits\n",
    "\tlogit_scale = clip_model.logit_scale.exp()\n",
    "\tlogits_per_text = torch.matmul(text_embeds, image_embeds.t().to(text_embeds.device)) * logit_scale.to(text_embeds.device)\n",
    "\n",
    "\treturn logits_per_text[0].tolist()\n",
    "\n",
    "zero_shot_scores = zero_shot_search(\"Preview thumbnails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use trained classifier to score images\n",
    "model = NsfwClassifier(768, 0.0, 2)\n",
    "model.load_state_dict(torch.load('classifier.pt'))\n",
    "model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def trained_filter(path, model) -> float:\n",
    "\tcursor.execute(\"SELECT embedding FROM images WHERE path = ?\", (path,))\n",
    "\tembedding = bytes(cursor.fetchone()[0])\n",
    "\tembedding = torch.frombuffer(bytearray(embedding), dtype=torch.float16)\n",
    "\tembedding = embedding.to(torch.float32)\n",
    "\tembedding = embedding.unsqueeze(0)\n",
    "\n",
    "\tlogits = model(embedding)\n",
    "\tprobabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "\treturn probabilities[:, 1].item()\n",
    "\n",
    "\n",
    "def get_trained_scores(paths: list[str | Path], model) -> OrderedDict[Path | str, dict]:\n",
    "\tscores = [trained_filter(path, model) for path in paths]\n",
    "\titems = list(zip(paths, scores))\n",
    "\titems = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\treturn OrderedDict((x[0], {\"score\": x[1]}) for x in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_existing_scores() -> dict[str, int]:\n",
    "\tif not Path(\"manual_scores.json\").exists():\n",
    "\t\treturn {}\n",
    "\n",
    "\twith open(\"manual_scores.json\", \"r\") as f:\n",
    "\t\treturn json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rater:\n",
    "\tpaths: OrderedDict[str | Path, dict]\n",
    "\n",
    "\tdef __init__(self, paths: OrderedDict[str | Path, dict], img_width: int, img_height: int):\n",
    "\t\tself.idx = -1\n",
    "\t\tself.paths = paths\n",
    "\t\tself.img_width = img_width\n",
    "\t\tself.img_height = img_height\n",
    "\n",
    "\t\tself.image_box = widgets.Image(width=img_width, height=img_height, format='jpg')\n",
    "\t\tself.grid_button = widgets.Button(description='Grid')\n",
    "\t\tself.none_button = widgets.Button(description='No grid')\n",
    "\t\tself.skip_button = widgets.Button(description='Skip')\n",
    "\n",
    "\t\tself.score_label = widgets.Label(value=\"Score: ?\")\n",
    "\n",
    "\t\tself.grid_button.on_click(lambda _: self.on_feedback(1))\n",
    "\t\tself.none_button.on_click(lambda _: self.on_feedback(0))\n",
    "\t\tself.skip_button.on_click(lambda _: self.next_image())\n",
    "\n",
    "\t\tself.vbox = widgets.VBox([widgets.HBox([self.grid_button, self.none_button, self.skip_button]), self.score_label, self.image_box])\n",
    "\t\n",
    "\tdef on_feedback(self, feedback: int):\n",
    "\t\tscores = read_existing_scores()\n",
    "\t\tpath = list(self.paths.keys())[self.idx]\n",
    "\t\tscores[str(path)] = feedback\n",
    "\n",
    "\t\t# Save feedback to database\n",
    "\t\twith open(\"manual_scores.tmp\", \"w\") as f:\n",
    "\t\t\tjson.dump(scores, f, indent=4)\n",
    "\t\t\n",
    "\t\tPath(\"manual_scores.tmp\").rename(\"manual_scores.json\")\n",
    "\t\t\n",
    "\t\tself.next_image()\n",
    "\t\n",
    "\tdef set_image(self, path: str | Path):\n",
    "\t\timage = Image.open(path)\n",
    "\t\tscale1 = self.img_width / image.width\n",
    "\t\tscale2 = self.img_height / image.height\n",
    "\t\twidth = int(image.width * min(scale1, scale2))\n",
    "\t\theight = int(image.height * min(scale1, scale2))\n",
    "\t\timage = image.resize((width, height))\n",
    "\t\twith io.BytesIO() as output:\n",
    "\t\t\timage.save(output, format=\"JPEG\")\n",
    "\t\t\tself.image_box.value = output.getvalue()\n",
    "\t\tself.image_box.width = width\n",
    "\t\tself.image_box.height = height\n",
    "\t\t#self.image_box.value = open(path, 'rb').read()\n",
    "\n",
    "\t\tscore = self.paths[path][\"score\"]\n",
    "\t\tself.score_label.value = f\"Score: {score:.4f}\"\n",
    "\t\n",
    "\tdef prev_image(self):\n",
    "\t\tself.idx = max(0, self.idx - 1)\n",
    "\t\tpath = list(self.paths.keys())[self.idx]\n",
    "\t\tself.set_image(path)\n",
    "\t\n",
    "\tdef next_image(self):\n",
    "\t\tratings = read_existing_scores()\n",
    "\t\tself.idx += 1\n",
    "\n",
    "\t\twhile self.idx < len(self.paths):\n",
    "\t\t\tpath = list(self.paths.keys())[self.idx]\n",
    "\n",
    "\t\t\tif path in ratings:\n",
    "\t\t\t\tself.idx += 1\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tself.set_image(path)\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\t\tself.image_box.value = None\n",
    "\t\tprint(\"Done!\")\n",
    "\n",
    "\n",
    "random_paths = random.sample(all_paths, 1000)\n",
    "random_paths = get_trained_scores(random_paths, model)\n",
    "rater = Rater(random_paths, 800, 800)\n",
    "rater.next_image()\n",
    "rater.vbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Rater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigRater:\n",
    "\tpaths: OrderedDict[Path | str, dict]\n",
    "\n",
    "\tdef __init__(self, paths: OrderedDict[Path | str, dict]):\n",
    "\t\tself.clicked_paths = []\n",
    "\n",
    "\t\t# Filter out paths that have already been rated\n",
    "\t\tscores = read_existing_scores()\n",
    "\t\tscored_paths = set(scores.keys())\n",
    "\t\tpaths = OrderedDict([(path, x) for path, x in paths.items() if path not in scored_paths])\n",
    "\n",
    "\t\tself.paths = paths\n",
    "\n",
    "\t\tself.display_rating_grid(list(self.paths.keys()), self.on_done_clicked, self.on_image_click)\n",
    "\n",
    "\tdef on_image_click(self, b):\n",
    "\t\timage_path = b.tooltip\n",
    "\t\tself.clicked_paths.append(image_path)\n",
    "\t\twidget = self.paths[image_path]['widget']\n",
    "\t\twidget.children[-1].style.button_color = 'red'\n",
    "\t\n",
    "\tdef on_done_clicked(self, b):\n",
    "\t\tself.vbox.close()\n",
    "\n",
    "\t\tself.display_rating_grid(self.clicked_paths, self.on_verify_clicked, None)\n",
    "\t\n",
    "\tdef on_verify_clicked(self, b):\n",
    "\t\tself.vbox.close()\n",
    "\n",
    "\t\t# Save feedback to database\n",
    "\t\tscores = read_existing_scores()\n",
    "\n",
    "\t\tfor path in self.clicked_paths:\n",
    "\t\t\tscores[path] = 1\n",
    "\n",
    "\t\t# Save feedback to database\n",
    "\t\twith open(\"manual_scores.tmp\", \"w\") as f:\n",
    "\t\t\tjson.dump(scores, f, indent=4)\n",
    "\n",
    "\t\tPath(\"manual_scores.tmp\").rename(\"manual_scores.json\")\n",
    "\t\n",
    "\tdef display_rating_grid(self, paths: list[Path | str], on_done, on_image_click):\n",
    "\t\timages = []\n",
    "\t\tfor path in tqdm(paths):\n",
    "\t\t\timage = Image.open(path)\n",
    "\t\t\timage = image.resize((256, 256)).convert(\"RGB\")\n",
    "\t\t\twith io.BytesIO() as output:\n",
    "\t\t\t\timage.save(output, format=\"JPEG\")\n",
    "\t\t\t\timage_bytes = output.getvalue()\n",
    "\t\t\t\n",
    "\t\t\twidget = widgets.Button(\n",
    "\t\t\t\tdescription='Grid',\n",
    "\t\t\t\tlayout=widgets.Layout(width='256px', height='25px', padding='0px', margin='0px'),\n",
    "\t\t\t\ttooltip=path,\n",
    "\t\t\t)\n",
    "\t\t\twidget.style.button_color = 'lightgray'\n",
    "\t\t\tif on_image_click is not None:\n",
    "\t\t\t\twidget.on_click(on_image_click)\n",
    "\n",
    "\t\t\timage = widgets.Image(value=image_bytes, format='jpeg')\n",
    "\n",
    "\t\t\tlabel = widgets.Label(value=f\"Score: {self.paths[path]['score']:.4f}\", layout=widgets.Layout(width='256px', height='20px', padding='0px', margin='0px'))\n",
    "\n",
    "\t\t\tvbox = widgets.VBox([label, image, widget])\n",
    "\t\t\timages.append(vbox)\n",
    "\t\t\tself.paths[path]['widget'] = vbox\n",
    "\n",
    "\t\tgrid = widgets.GridBox(\n",
    "\t\t\timages,\n",
    "\t\t\tlayout=widgets.Layout(\n",
    "\t\t\t\tgrid_template_columns='repeat(auto-fit, 256px)',\n",
    "\t\t\t\tgrid_gap='10px'\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\n",
    "\t\tdone_button = widgets.Button(description='Done')\n",
    "\t\tdone_button.on_click(on_done)\n",
    "\t\tself.vbox = widgets.VBox([grid, done_button])\n",
    "\t\tself.image_widgets = images\n",
    "\n",
    "\t\tdisplay(self.vbox)\n",
    "\n",
    "\n",
    "random_paths = random.sample(all_paths, 256)\n",
    "random_paths = get_trained_scores(random_paths, model)\n",
    "big_rater = BigRater(random_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check data by visualizing all of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = defaultdict(list)\n",
    "for path, score in read_existing_scores().items():\n",
    "\tgroups[score].append(path)\n",
    "\n",
    "html = \"<html><head><style>img { width: 200px; height: 200px; }</style>\"\n",
    "html += \"<script>function copyToClipboard(text) { navigator.clipboard.writeText(text); }</script>\"\n",
    "html += \"</head><body>\"\n",
    "\n",
    "for score, paths in groups.items():\n",
    "\thtml += f\"<h1>{score}</h1>\"\n",
    "\t\n",
    "\tfor path in tqdm(paths):\n",
    "\t\timage = Image.open(path)\n",
    "\t\tscale = 256 / max(image.width, image.height)\n",
    "\t\timage = image.resize((int(image.width * scale), int(image.height * scale)))\n",
    "\t\twith io.BytesIO() as output:\n",
    "\t\t\timage.save(output, format=\"WEBP\")\n",
    "\t\t\tcontents = output.getvalue()\n",
    "\t\t\tb64 = base64.b64encode(contents).decode()\n",
    "\t\t\n",
    "\t\thtml += f'<img src=\"data:image/webp;base64,{b64}\" onclick=\"copyToClipboard(\\'{path}\\')\" />'\n",
    "\t\n",
    "html += \"</body></html>\"\n",
    "\n",
    "with open(\"output.html\", \"w\") as f:\n",
    "\tf.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmpenv5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
