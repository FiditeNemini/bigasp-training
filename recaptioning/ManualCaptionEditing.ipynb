{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect some manually editted captions to help zero-shot and fine-tune LLMs for cleaning up the captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from pathlib import Path\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "import yaml\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import openai\n",
    "import json\n",
    "#from mistralai import Mistral\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "#import mistralai\n",
    "import time\n",
    "import difflib\n",
    "import textwrap\n",
    "import requests\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat_tokenizer = get_chat_template(\n",
    "#\ttokenizer,\n",
    "#\tchat_template = \"llama-3.1\",\n",
    "#)\n",
    "\n",
    "CHAT_PROMPT = \"\"\"Please edit the user's provided image descriptions following the guidelines below:\n",
    "1. The edits should be minimal and not affect the details or accuracy of the description.\n",
    "2. Remove any mention of the image's resolution, but don't remove information about the image's quality.\n",
    "3. Edit out any self-referential language. For example: \"this is a digital painting\" -> \"a digital painting\", \"In this photo a woman stands\" -> \"photo of a woman standing\", etc.\n",
    "4. Randomly swap in informal synonyms for things like \"penis\", \"vulva\", etc.\n",
    "5. Do not modify anything in quotes that are describing text in the image.\n",
    "6. Randomly swap the word \"photograph\" to \"photo\".\n",
    "7. Remove any duplicates from the description if the description repeats itself.\n",
    "8. When you make edits, make sure to maintain the original meaning of the sentence, and minimize the number of changes.\n",
    "9. Only update the grammer if necessary. Do NOT fix any grammar mistakes or oddness that were in the original description. Some of them may be MidJourney prompts or lists of tags.\n",
    "\n",
    "Respond with only the edited image description.\n",
    "\"\"\"\n",
    "\n",
    "ADD_PROMPT = \"\"\"Please edit the user's provided image descriptions following the guidelines below:\n",
    "1. If the description does not mention that there is a watermark in the image, add a mention of a watermark.\n",
    "2. If the description already mentions a watermark, no changes are needed. Leave the description as is.\n",
    "3. If the description says there is no watermark, fix the description to mention a watermark.\n",
    "4. Fix any conflicting information about the watermark in the description.\n",
    "5. When you make edits, make sure to maintain the original meaning of the sentence, and minimize the number of changes.\n",
    "6. Only update the grammer if necessary. Do NOT fix any grammar mistakes or oddness that were in the original description. Some of them may be MidJourney prompts or lists of tags.\n",
    "\n",
    "Respond with only the edited image description, or the original description if no changes were needed.\n",
    "\"\"\"\n",
    "\n",
    "REMOVE_PROMPT = \"\"\"Please edit the user's provided image descriptions following the guidelines below:\n",
    "1. If the description mentions that there is a watermark in the image, remove the mention of the watermark.\n",
    "2. If the description does not mention a watermark, no changes are needed. Leave the description as is.\n",
    "3. If the description says there is no watermark, no changes are needed. Leave the description as is.\n",
    "4. Fix any conflicting information about the lack of a watermark in the description.\n",
    "5. When you make edits, make sure to maintain the original meaning of the sentence, and minimize the number of changes.\n",
    "6. Only update the grammer if necessary. Do NOT fix any grammar mistakes or oddness that were in the original description. Some of them may be MidJourney prompts or lists of tags.\n",
    "\n",
    "Respond with only the edited image description, or the original description if no changes were needed.\n",
    "\"\"\"\n",
    "\n",
    "SOURCE_PROMPT = \"\"\"Please edit the user's provided image descriptions following these guidelines:\n",
    "1. In some way, add to the description so that it mentions that the image is from \"{source}\".\n",
    "2. If the source starts with \"r/\" then randomly also add a mention of \"reddit\" to the description.\n",
    "3. Your edits should be minimal and not affect the details or accuracy of the description in any way.\n",
    "4. Only update the grammer if necessary. Do NOT fix any grammar mistakes or oddness that were in the original description. Some of them may be MidJourney prompts or lists of tags.\n",
    "5. There are a variety of ways that you can add this information to the description. Be creative and make sure to maintain the original meaning of the description.\n",
    "6. Randomly change the capitalization of the source name in the description.\n",
    "\n",
    "Respond with only the edited image description.\"\"\"\n",
    "\n",
    "\n",
    "def format_messages(operator: str, caption: str, extra: str | None, extra_prompt: str | None) -> list[dict]:\n",
    "\tif operator == \"add-watermark\":\n",
    "\t\tsystem_message = ADD_PROMPT\n",
    "\telif operator == \"remove-watermark\":\n",
    "\t\tsystem_message = REMOVE_PROMPT\n",
    "\telif operator == \"add-source\":\n",
    "\t\tsystem_message = SOURCE_PROMPT\n",
    "\telse:\n",
    "\t\traise ValueError(f\"Unknown operator: {operator}\")\n",
    "\t\n",
    "\tif operator == \"add-source\":\n",
    "\t\tassert extra is not None\n",
    "\t\tsystem_message = system_message.format(source=extra)\n",
    "\t\n",
    "\tif extra_prompt is not None:\n",
    "\t\tsystem_message = extra_prompt + \" \" + system_message\n",
    "\t\n",
    "\treturn [\n",
    "\t\t{\"role\": \"system\", \"content\": system_message.strip()},\n",
    "\t\t{\"role\": \"user\", \"content\": caption.strip()},\n",
    "\t]\n",
    "\n",
    "\n",
    "def ask_our_model(operator: str, caption: str, extra: str | None):\n",
    "\tclient = openai.OpenAI(api_key=\"EMPTY\", base_url=\"http://localhost:8000/v1\")\n",
    "\n",
    "\tif operator == \"add-watermark\":\n",
    "\t\tmodel = \"watermark\"\n",
    "\telif operator == \"remove-watermark\":\n",
    "\t\tmodel = \"watermark\"\n",
    "\telif operator == \"add-source\":\n",
    "\t\tmodel = \"add-source\"\n",
    "\telse:\n",
    "\t\traise ValueError(f\"Unknown operator: {operator}\")\n",
    "\n",
    "\tchat_response = client.chat.completions.create(\n",
    "\t\tmodel=model,\n",
    "\t\tmessages=format_messages(operator, caption, extra, None),\n",
    "\t\ttemperature=0.6,\n",
    "\t\ttop_p=0.9,\n",
    "\t\t#top_k=0,\n",
    "\t\tmax_tokens=512,\n",
    "\t)\n",
    "\n",
    "\treturn chat_response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_MODELS = {\n",
    "\t\"openai/gpt-4o-2024-08-06\": {\"temperature\": 1.0, \"top_p\": 1.0 },\n",
    "\t#\"openai/o1-preview\": {\"temperature\": 1.0, \"top_p\": 1.0 },\n",
    "\t\"sao10k/l3.1-euryale-70b\": {\"temperature\": 0.6, \"top_p\": 0.9 },\n",
    "\t\"meta-llama/llama-3.1-70b-instruct:free\": {\"temperature\": 0.6, \"top_p\": 0.9 },\n",
    "\t\"meta-llama/llama-3.1-405b-instruct:free\": {\"temperature\": 0.6, \"top_p\": 0.9 },\n",
    "\t\"nousresearch/hermes-3-llama-3.1-405b:free\": {\"temperature\": 0.6, \"top_p\": 0.9 },\n",
    "}\n",
    "\n",
    "def ask_openrouter(operator: str, caption: str, extra: str | None) -> str:\n",
    "\tmodel_name = random.choice(list(OPENROUTER_MODELS.keys()))\n",
    "\tmodel_params = OPENROUTER_MODELS[model_name]\n",
    "\n",
    "\tprint(f\"Using model {model_name}\")\n",
    "\n",
    "\tclient = openai.OpenAI(api_key=os.getenv(\"OPENROUTER_API_KEY\"), base_url=\"https://openrouter.ai/api/v1\")\n",
    "\n",
    "\ttry:\n",
    "\t\tchat_response = client.chat.completions.create(\n",
    "\t\t\tmodel=model_name,\n",
    "\t\t\tmessages=format_messages(operator, caption, extra, None),\n",
    "\t\t\ttemperature=model_params[\"temperature\"],\n",
    "\t\t\ttop_p=model_params[\"top_p\"],\n",
    "\t\t\t#top_k=0,\n",
    "\t\t\tmax_tokens=512,\n",
    "\t\t)\n",
    "\n",
    "\t\tresponse = chat_response.choices[0].message.content\n",
    "\t\tassert isinstance(response, str)\n",
    "\t\treturn response\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\treturn \"Sorry, I'm having trouble connecting to the model. Please try again later.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(dbname='postgres', user='postgres', host=str(Path.cwd().parent / \"pg-socket\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPERATOR = 'remove_bullshit'\n",
    "#OPERATOR = 'add-watermark'\n",
    "#OPERATOR = 'remove-watermark'\n",
    "OPERATOR = 'add-source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTIVE_EDITING = set([\"features\",\"depicts\"])\n",
    "SYNONYMS = yaml.safe_load(Path(\"synonyms.yaml\").read_text())\n",
    "SOURCES = {'fansly', 'flickr', 'onlyfans', 'unsplash'}\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "\tcur.execute(\"SELECT DISTINCT subreddit FROM images WHERE subreddit IS NOT NULL\")\n",
    "\tSUBREDDITS = set(row[0] for row in cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNC = re.compile(r'[,.!?:;]')\n",
    "\n",
    "def is_repeating(caption: str) -> bool:\n",
    "\t# Split on any punctuation\n",
    "\tpieces = PUNC.split(caption)\n",
    "\tcounts = defaultdict(int)\n",
    "\tfor piece in pieces:\n",
    "\t\tcounts[piece.strip().lower()] += 1\n",
    "\t\n",
    "\tif any(count > 2 for count in counts.values()):\n",
    "\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "\n",
    "def check_words_in_quotes(input_string: str, words_list: list[str]) -> bool:\n",
    "\twords_pattern = '|'.join(map(re.escape, words_list))\n",
    "\n",
    "\t# Regular expression to check if any word from the list is between quotes\n",
    "\tpattern = rf'[\"\\'][^s]([^\"\\']*({words_pattern})[^\"\\']*)[\"\\']'\n",
    "\n",
    "\tmatch = re.search(pattern, input_string.lower())\n",
    "\treturn bool(match)\n",
    "\n",
    "\n",
    "keywords = ['image']\n",
    "syns = list(SYNONYMS.keys())\n",
    "\n",
    "with conn.cursor('caption-editing') as cur:\n",
    "\t#cur.execute(\"SELECT caption FROM images WHERE caption IS NOT NULL AND caption LIKE '%this%'\")\n",
    "\t#cur.execute(\"SELECT caption FROM images WHERE caption IS NOT NULL\")\n",
    "\tcur.execute(\"SELECT caption_3 FROM images WHERE caption_3 IS NOT NULL\")\n",
    "\t#cur.execute(\"SELECT caption_2 FROM images WHERE caption_2 IS NOT NULL\")\n",
    "\t#cur.execute(\"SELECT caption FROM images WHERE caption IS NOT NULL AND (caption LIKE '%feature%' OR caption LIKE '%depict%' OR caption LIKE '%likely%' OR caption LIKE '%possibly%' OR caption LIKE '%probably%' OR caption LIKE '%resolution%' OR caption LIKE '%appear%' OR caption LIKE '%seem%')\")\n",
    "\tg_captions = [row[0] for row in cur]\n",
    "\t#captions = [caption for caption in captions if any(keyword in caption.lower() for keyword in keywords)]\n",
    "\t#captions = [caption for caption in captions if is_repeating(caption)]\n",
    "\t#captions = [caption for caption in captions if check_words_in_quotes(caption, syns)]\n",
    "\t#g_captions = [caption for caption in g_captions if 'watermark' in caption.lower()]\n",
    "\t#g_captions = [caption for caption in g_captions if caption.lower().count('watermark') > 1]\n",
    "\n",
    "\tcur.execute(\"SELECT caption, recaptioned FROM recaption_dataset WHERE operator = %s\", (OPERATOR,))\n",
    "\trecaptions = {row[0]: row[1] for row in cur}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_caption(caption: str) -> str:\n",
    "\twords = caption.split(\" \")\n",
    "\tupdated_words = []\n",
    "\n",
    "\tfor word in words:\n",
    "\t\tif random.random() < 0.5:\n",
    "\t\t\tupdated_words.append(word)\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tfor k, v in SYNONYMS.items():\n",
    "\t\t\tif k not in word.lower():\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tnew_word = random.choice(v)\n",
    "\n",
    "\t\t\t# Match case\n",
    "\t\t\tif word.strip().isupper():\n",
    "\t\t\t\tnew_word = new_word.upper()\n",
    "\t\t\telif word.strip()[0].isupper():\n",
    "\t\t\t\tnew_word = new_word.capitalize()\n",
    "\n",
    "\t\t\tprint(f\"Replacing {k} with {new_word} in {word}\")\n",
    "\t\t\t\n",
    "\t\t\tupdated_words.append(word.lower().replace(k, new_word))\n",
    "\t\t\tbreak\n",
    "\t\telse:\n",
    "\t\t\tupdated_words.append(word)\n",
    "\t\n",
    "\tmodified_caption = \" \".join(updated_words).strip()\n",
    "\n",
    "\treturn modified_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionEditor:\n",
    "\tdef __init__(self, auto_modify: bool, show_repeats: bool, keywords_to_highlight: set[str], invert_button: bool, sources: set[str]):\n",
    "\t\tself.auto_modify = auto_modify\n",
    "\t\tself.show_repeats = show_repeats\n",
    "\t\tself.keywords_to_highlight = keywords_to_highlight\n",
    "\t\tself.sources = sources\n",
    "\n",
    "\t\tself.counter_label = widgets.Label(value=\"0 / 0\")\n",
    "\t\tself.current_operator = widgets.Label(value=f\"Operator: {OPERATOR}\")\n",
    "\t\tself.sym_label = widgets.Label(value=\"\")\n",
    "\t\tself.original_caption = widgets.Textarea(layout=widgets.Layout(width='100%', height='100px'), disabled=True)\n",
    "\t\tself.text_area = widgets.Textarea(layout=widgets.Layout(width='100%', height='100px'))\n",
    "\t\tself.highlighted_diff = widgets.HTML()\n",
    "\t\tself.repeat_area = widgets.Textarea(layout=widgets.Layout(width='100%', height='100px'), disabled=True)\n",
    "\t\tself.submit_button = widgets.Button(description='Submit')\n",
    "\t\tself.submit_button.on_click(self.on_submit)\n",
    "\t\tself.skip_button = widgets.Button(description='Skip')\n",
    "\t\tself.skip_button.on_click(lambda b: self.next_caption())\n",
    "\t\tself.chatgpt_button = widgets.Button(description='Ask ChatGPT')\n",
    "\t\tself.chatgpt_button.on_click(lambda b: self.ask_chatgpt())\n",
    "\n",
    "\t\tif invert_button:\n",
    "\t\t\tself.invert_button = widgets.Button(description='Submit & Invert')\n",
    "\t\t\tself.invert_button.on_click(self.on_submit_and_invert)\n",
    "\n",
    "\t\tself.submit_and_ask_button = widgets.Button(description='Submit & ChatGPT')\n",
    "\t\tself.submit_and_ask_button.on_click(self.on_submit_and_ask)\n",
    "\n",
    "\t\tui = [\n",
    "\t\t\tself.counter_label,\n",
    "\t\t\tself.current_operator,\n",
    "\t\t\tself.sym_label,\n",
    "\t\t\tself.original_caption,\n",
    "\t\t\tself.text_area,\n",
    "\t\t\tself.highlighted_diff,\n",
    "\t\t]\n",
    "\n",
    "\t\tif self.show_repeats:\n",
    "\t\t\tui.append(self.repeat_area)\n",
    "\n",
    "\t\tui.extend([self.submit_button, self.submit_and_ask_button, self.skip_button, self.chatgpt_button])\n",
    "\n",
    "\t\tif invert_button:\n",
    "\t\t\tui.append(self.invert_button)\n",
    "\n",
    "\t\tdisplay(widgets.VBox(ui))\n",
    "\n",
    "\t\tself.text_area.observe(self.update_highlight, names='value')\n",
    "\n",
    "\t\tself.next_caption()\n",
    "\t\n",
    "\tdef ask_chatgpt(self):\n",
    "\t\tself.text_area.value = \"Asking ChatGPT...\"\n",
    "\t\t#edited_caption = ask_openrouter(OPERATOR, self.current_caption, self.sym_label.value.split(\": \")[1].strip())\n",
    "\t\tedited_caption = ask_our_model(OPERATOR, self.current_caption, self.sym_label.value.split(\": \")[1].strip())\n",
    "\t\tself.text_area.value = edited_caption\n",
    "\t\n",
    "\tdef show_caption(self, caption: str):\n",
    "\t\t# Automatic synonym replacement\n",
    "\t\tif self.auto_modify:\n",
    "\t\t\tmodified_caption = modify_caption(caption)\n",
    "\t\telse:\n",
    "\t\t\tmodified_caption = caption\n",
    "\n",
    "\t\t# Selective editting\n",
    "\t\tselective_editing = []\n",
    "\n",
    "\t\tif len(self.sources) > 0:\n",
    "\t\t\t# Downweight subreddits\n",
    "\t\t\tsources = list(self.sources)\n",
    "\t\t\tweights = [0.2 if \"r/\" in source else 1.0 for source in sources]\n",
    "\t\t\tsource = random.choices(sources, weights=weights)[0]\n",
    "\t\t\tselective_editing.append(source)\n",
    "\t\telse:\n",
    "\t\t\tfor key in SELECTIVE_EDITING:\n",
    "\t\t\t\tif random.random() < 0.5:\n",
    "\t\t\t\t\tselective_editing.append(key)\n",
    "\n",
    "\t\tself.original_caption.value = caption\n",
    "\t\tself.text_area.value = modified_caption\n",
    "\t\tself.sym_label.value = f\"Selective editing: {', '.join(selective_editing)}\"\n",
    "\t\tself.counter_label.value = f\"Completed / Total: {len(recaptions)} / {len(g_captions)}\"\n",
    "\t\n",
    "\tdef next_caption(self):\n",
    "\t\tremaining = [caption for caption in g_captions if caption not in recaptions]\n",
    "\t\tif not remaining:\n",
    "\t\t\tprint(\"No more captions to edit!\")\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\t\tself.current_caption = random.choice(remaining)\n",
    "\t\t\n",
    "\t\tself.show_caption(self.current_caption)\n",
    "\t\n",
    "\tdef on_submit(self, b):\n",
    "\t\trecaptions[self.current_caption] = self.text_area.value\n",
    "\t\textra = None\n",
    "\n",
    "\t\tif OPERATOR == 'add-source':\n",
    "\t\t\textra = self.sym_label.value.split(\": \")[1].strip()\n",
    "\n",
    "\t\twith conn.cursor() as cur:\n",
    "\t\t\tcur.execute(\"INSERT INTO recaption_dataset (caption, recaptioned, operator, extra_1) VALUES (%s, %s, %s, %s)\", (self.current_caption, self.text_area.value, OPERATOR, extra))\n",
    "\t\t\tconn.commit()\n",
    "\n",
    "\t\tself.next_caption()\n",
    "\t\n",
    "\tdef on_submit_and_ask(self, b):\n",
    "\t\tself.on_submit(b)\n",
    "\t\tself.ask_chatgpt()\n",
    "\t\n",
    "\tdef on_submit_and_invert(self, b):\n",
    "\t\trecaptions[self.current_caption] = self.text_area.value\n",
    "\n",
    "\t\tif OPERATOR == 'remove-watermark':\n",
    "\t\t\tinverted_operator = 'add-watermark'\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"Don't know how to invert operator {OPERATOR}\")\n",
    "\t\t\n",
    "\t\twith conn.cursor() as cur:\n",
    "\t\t\tcur.execute(\"INSERT INTO recaption_dataset (caption, recaptioned, operator) VALUES (%s, %s, %s)\", (self.current_caption, self.text_area.value, OPERATOR))\n",
    "\t\t\tcur.execute(\"INSERT INTO recaption_dataset (caption, recaptioned, operator) VALUES (%s, %s, %s)\", (self.text_area.value, self.current_caption, inverted_operator))\n",
    "\t\t\tconn.commit()\n",
    "\t\t\n",
    "\t\tself.next_caption()\n",
    "\t\n",
    "\tdef update_highlight(self, change):\n",
    "\t\toriginal = self.current_caption\n",
    "\t\tmodified = self.text_area.value\n",
    "\t\thighlighted_html = self.highlight_changes_html(original, modified)\n",
    "\t\tself.highlighted_diff.value = highlighted_html\n",
    "\n",
    "\t\trepeats = get_repeats(modified)\n",
    "\t\tself.repeat_area.value = \"\\n\".join(repeats)\n",
    "\t\n",
    "\tdef highlight_changes_html(self, original: str, modified: str) -> str:\n",
    "\t\toriginal_tokens = self.tokenize(original)\n",
    "\t\tmodified_tokens = self.tokenize(modified)\n",
    "\n",
    "\t\tdiff = difflib.ndiff(original_tokens, modified_tokens)\n",
    "\t\tresult = []\n",
    "\n",
    "\t\tfor word in diff:\n",
    "\t\t\ttoken = word[2:]\n",
    "\t\t\tif word.startswith('  '):  # no change\n",
    "\t\t\t\tclean_token = token.strip()\n",
    "\t\t\t\tif clean_token.lower() in self.keywords_to_highlight:\n",
    "\t\t\t\t\tresult.append(f'<span style=\"background-color: yellow;\">{token}</span>')\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tresult.append(token)\n",
    "\t\t\telif word.startswith('- '):  # deletion\n",
    "\t\t\t\tresult.append(f'<span style=\"color: red; text-decoration: line-through;\">{token}</span>')\n",
    "\t\t\telif word.startswith('+ '):  # addition\n",
    "\t\t\t\tresult.append(f'<span style=\"color: green; font-weight: bold;\">{token}</span>')\n",
    "\t\t\n",
    "\t\treturn ''.join(result)\n",
    "\t\n",
    "\t@staticmethod\n",
    "\tdef tokenize(text: str) -> list[str]:\n",
    "\t\t#return re.findall(r'\\w+|[^\\w\\s]', text, re.UNICODE)\n",
    "\t\treturn re.findall(r'\\s+|\\w+|[^\\w\\s]', text, re.UNICODE)\n",
    "\n",
    "\n",
    "def get_repeats(caption: str) -> list[str]:\n",
    "\tpieces = [x.strip().lower() for x in PUNC.split(caption)]\n",
    "\trepeats = []\n",
    "\n",
    "\tfor piece in pieces:\n",
    "\t\tif pieces.count(piece) > 1:\n",
    "\t\t\trepeats.append(piece)\n",
    "\t\n",
    "\treturn repeats\n",
    "\n",
    "\n",
    "auto_modify = False\n",
    "show_repeats = False\n",
    "keywords_to_highlight = set()\n",
    "invert_button = False\n",
    "sources = set()\n",
    "\n",
    "if OPERATOR == 'remove_bullshit':\n",
    "\tauto_modify = True\n",
    "\tshow_repeats = True\n",
    "\tkeywords_to_highlight = {\"resolution\", \"image\", \"likely\", \"possibly\", \"probably\", \"appear\", \"seem\", \"this\", \"features\", \"depicts\", \"the photo\", \"the photograph\"}\n",
    "elif OPERATOR == 'add-watermark':\n",
    "\tkeywords_to_highlight = {\"watermark\", \"watermarks\", \"watermarked\", \"logo\", \"logos\"}\n",
    "elif OPERATOR == 'remove-watermark':\n",
    "\tkeywords_to_highlight = {\"watermark\", \"watermarks\", \"watermarked\", \"logo\", \"logos\"}\n",
    "\tinvert_button = True\n",
    "elif OPERATOR == 'add-source':\n",
    "\tsources = SOURCES.union({f\"r/{sub.lower()}\" for sub in SUBREDDITS})\n",
    "\tsources.add(\"reddit\")\n",
    "\n",
    "CaptionEditor(auto_modify=auto_modify, show_repeats=show_repeats, keywords_to_highlight=keywords_to_highlight, invert_button=invert_button, sources=sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats\n",
    "syn_counts = {k: [0, 0] for k in SYNONYMS.keys()}\n",
    "syn_counts['features'] = [0, 0]\n",
    "\n",
    "vulgar_count = defaultdict(int)\n",
    "\n",
    "for original, edited in recaptions.items():\n",
    "\toriginal = PUNC.sub(\"\", original).lower()\n",
    "\tedited = PUNC.sub(\"\", edited).lower()\n",
    "\toriginal_words = original.split()\n",
    "\tedited_words = edited.split()\n",
    "\n",
    "\tfor keyword in syn_counts.keys():\n",
    "\t\toriginal_count = sum(1 for word in original_words if word == keyword)\n",
    "\t\tedited_count = sum(1 for word in edited_words if word == keyword)\n",
    "\t\tsyn_counts[keyword][0] += original_count\n",
    "\t\tsyn_counts[keyword][1] += edited_count\n",
    "\t\n",
    "\tfor k, values in SYNONYMS.items():\n",
    "\t\tif not any(k in word for word in original_words):\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\tfor v in values:\n",
    "\t\t\tcount = sum(1 for word in edited_words if word == v)\n",
    "\t\t\tvulgar_count[f\"{k}->{v}\"] += count\n",
    "\n",
    "for key, (original_count, edited_count) in syn_counts.items():\n",
    "\tprint(f\"{key}: {edited_count} / {original_count} ({edited_count / max(0.0001, original_count) * 100:.2f}%)\")\n",
    "\n",
    "print()\n",
    "print(\"Vulgar counts:\")\n",
    "for key, count in vulgar_count.items():\n",
    "\tprint(f\"{key}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add watermark: 195 / 394 (49.49%)\n",
      "Remove watermark: 179 / 358 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "\tcur.execute(\"SELECT caption, recaptioned FROM recaption_dataset WHERE operator = 'add-watermark'\")\n",
    "\tadd_watermark_recaptions = {row[0]: row[1] for row in cur}\n",
    "\tcur.execute(\"SELECT caption, recaptioned FROM recaption_dataset WHERE operator = 'remove-watermark'\")\n",
    "\tremove_watermark_recaptions = {row[0]: row[1] for row in cur}\n",
    "\n",
    "add_watermark_recaptions_changes = sum(1 for k, v in add_watermark_recaptions.items() if k != v)\n",
    "remove_watermark_recaptions_changes = sum(1 for k, v in remove_watermark_recaptions.items() if k != v)\n",
    "\n",
    "print(f\"Add watermark: {add_watermark_recaptions_changes} / {len(add_watermark_recaptions)} ({add_watermark_recaptions_changes / max(0.0001, len(add_watermark_recaptions)) * 100:.2f}%)\")\n",
    "print(f\"Remove watermark: {remove_watermark_recaptions_changes} / {len(remove_watermark_recaptions)} ({remove_watermark_recaptions_changes / max(0.0001, len(remove_watermark_recaptions)) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for caption in random.sample([caption for caption in captions if \"watermark\" in caption.lower()], 32):\n",
    "\tprint(caption)\n",
    "\tprint(\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write training data for add-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PROMPT = \"\"\"Please edit the user's provided image descriptions following these guidelines:\n",
    "1. In some way, add to the description so that it mentions that the image is from \"{source}\".\n",
    "2. If the source starts with \"r/\" then randomly also add a mention of \"reddit\" to the description.\n",
    "3. Your edits should be minimal and not affect the details or accuracy of the description in any way.\n",
    "4. Only update the grammer if necessary. Do NOT fix any grammar mistakes or oddness that were in the original description. Some of them may be MidJourney prompts or lists of tags.\n",
    "5. There are a variety of ways that you can add this information to the description. Be creative and make sure to maintain the original meaning of the description.\n",
    "6. Randomly change the capitalization of the source name in the description.\n",
    "\n",
    "Respond with only the edited image description.\"\"\"\n",
    "\n",
    "def write_training(filename: str, examples: list[tuple[str, str, str]]):\n",
    "\twith open(filename, 'w') as f:\n",
    "\t\tfor k, v, source in examples:\n",
    "\t\t\texample = {\n",
    "\t\t\t\t\"messages\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"system\",\n",
    "\t\t\t\t\t\t\"content\": SOURCE_PROMPT.format(source=source).strip(),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\t\t\"content\": k.strip(),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"assistant\",\n",
    "\t\t\t\t\t\t\"content\": v.strip(),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t]\n",
    "\t\t\t}\n",
    "\t\t\tf.write(json.dumps(example) + \"\\n\")\n",
    "\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "\tcur.execute(\"SELECT caption, recaptioned, extra_1 FROM recaption_dataset WHERE operator = 'add-source'\")\n",
    "\texamples = [row for row in cur]\n",
    "\n",
    "random.shuffle(examples)\n",
    "\n",
    "n_test = 32\n",
    "test_examples = examples[:n_test]\n",
    "train_examples = examples[n_test:]\n",
    "\n",
    "write_training(\"source-train.jsonl\", train_examples)\n",
    "write_training(\"source-test.jsonl\", test_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write training data for add/remove watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_PROMPT = \"\"\"Please edit the user's provided image descriptions following the guidelines below:\n",
    "1. If the description does not mention that there is a watermark in the image, add a mention of a watermark.\n",
    "2. If the description already mentions a watermark, no changes are needed. Leave the description as is.\n",
    "3. If the description says there is no watermark, fix the description to mention a watermark.\n",
    "4. Fix any conflicting information about the watermark in the description.\n",
    "5. When you make edits, make sure to maintain the original meaning of the sentence, and minimize the number of changes.\n",
    "6. Only update the grammer if necessary. Do NOT fix any grammar mistakes or oddness that were in the original description. Some of them may be MidJourney prompts or lists of tags.\n",
    "\n",
    "Respond with only the edited image description, or the original description if no changes were needed.\n",
    "\"\"\"\n",
    "\n",
    "REMOVE_PROMPT = \"\"\"Please edit the user's provided image descriptions following the guidelines below:\n",
    "1. If the description mentions that there is a watermark in the image, remove the mention of the watermark.\n",
    "2. If the description does not mention a watermark, no changes are needed. Leave the description as is.\n",
    "3. If the description says there is no watermark, no changes are needed. Leave the description as is.\n",
    "4. Fix any conflicting information about the lack of a watermark in the description.\n",
    "5. When you make edits, make sure to maintain the original meaning of the sentence, and minimize the number of changes.\n",
    "6. Only update the grammer if necessary. Do NOT fix any grammar mistakes or oddness that were in the original description. Some of them may be MidJourney prompts or lists of tags.\n",
    "\n",
    "Respond with only the edited image description, or the original description if no changes were needed.\n",
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "\tcur.execute(\"SELECT caption, recaptioned FROM recaption_dataset WHERE operator = 'add-watermark'\")\n",
    "\tadd_watermark_examples = [(ADD_PROMPT, row[0], row[1]) for row in cur]\n",
    "\tcur.execute(\"SELECT caption, recaptioned FROM recaption_dataset WHERE operator = 'remove-watermark'\")\n",
    "\tremove_watermark_examples = [(REMOVE_PROMPT, row[0], row[1]) for row in cur]\n",
    "\n",
    "\n",
    "def write_training(filename: str, examples: list[tuple[str, str, str]]):\n",
    "\twith open(filename, 'w') as f:\n",
    "\t\tfor prompt, k, v in examples:\n",
    "\t\t\texample = {\n",
    "\t\t\t\t\"messages\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"system\",\n",
    "\t\t\t\t\t\t\"content\": prompt.strip(),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\t\t\"content\": k.strip(),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"assistant\",\n",
    "\t\t\t\t\t\t\"content\": v.strip(),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t]\n",
    "\t\t\t}\n",
    "\t\t\tf.write(json.dumps(example) + \"\\n\")\n",
    "\n",
    "n_test = 16\n",
    "random.shuffle(add_watermark_examples)\n",
    "random.shuffle(remove_watermark_examples)\n",
    "test_examples = add_watermark_examples[:n_test] + remove_watermark_examples[:n_test]\n",
    "train_examples = add_watermark_examples[n_test:] + remove_watermark_examples[n_test:]\n",
    "random.shuffle(test_examples)\n",
    "random.shuffle(train_examples)\n",
    "\n",
    "write_training(\"watermark-train.jsonl\", train_examples)\n",
    "write_training(\"watermark-test.jsonl\", test_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write training data for remove_bullshit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"Please edit the user's provided image descriptions following the guidelines below:\n",
    "1. The edits should be minimal and not affect the details or accuracy of the description.\n",
    "2. Remove any mention of the image's resolution, but don't remove information about the image's quality.\n",
    "3. Edit out any self-referential language. For example: \"this is a digital painting\" -> \"a digital painting\", \"In this photo a woman stands\" -> \"photo of a woman standing\", etc.\n",
    "4. Randomly swap in informal synonyms for things like \"penis\", \"vulva\", etc.\n",
    "5. Do not modify anything in quotes that are describing text in the image.\n",
    "6. Randomly swap the word \"photograph\" to \"photo\".\n",
    "7. Remove any duplicates from the description if the description repeats itself.\n",
    "8. When you make edits, make sure to maintain the original meaning of the sentence, and minimize the number of changes.\n",
    "9. Only update the grammer if necessary. Do NOT fix any grammar mistakes or oddness that were in the original description. Some of them may be MidJourney prompts or lists of tags.\n",
    "\n",
    "Respond with only the edited image description.\n",
    "\"\"\"\n",
    "\n",
    "def write_training(filename: str, examples: list[tuple[str, str]]):\n",
    "\twith open(filename, 'w') as f:\n",
    "\t\tfor k, v in examples:\n",
    "\t\t\texample = {\n",
    "\t\t\t\t\"messages\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"system\",\n",
    "\t\t\t\t\t\t\"content\": PROMPT,\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\t\t\"content\": k.strip(),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"role\": \"assistant\",\n",
    "\t\t\t\t\t\t\"content\": v.strip(),\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t]\n",
    "\t\t\t}\n",
    "\t\t\tf.write(json.dumps(example) + \"\\n\")\n",
    "\n",
    "\n",
    "examples = [(k, v) for k, v in recaptions.items()]\n",
    "random.shuffle(examples)\n",
    "\n",
    "n_test = 32\n",
    "test_examples = examples[:n_test]\n",
    "train_examples = examples[n_test:]\n",
    "\n",
    "write_training(\"train.jsonl\", train_examples)\n",
    "write_training(\"test.jsonl\", test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in recaptions.items():\n",
    "\tprint(f\"Original: {k}\")\n",
    "\tprint(f\"Rewrite: {v}\")\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmpenv5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
